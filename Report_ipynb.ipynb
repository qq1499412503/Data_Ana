{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "“A1_ReportDraft.ipynb”的副本",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qq1499412503/Data_Ana/blob/master/%E2%80%9CA1_ReportDraft_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r6FfmAR3_Jl",
        "colab_type": "text"
      },
      "source": [
        "# Draft and Experiment Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeWgnsdJ3_Jm",
        "colab_type": "text"
      },
      "source": [
        "1. First impression\n",
        "    * What is my chosen paper to read?\n",
        "    Generative Adversarial Nets\n",
        "    \n",
        "    * What type of the main contribution the paper has made?\n",
        "        - A theory or proposition (revealing something, from unknown to known)\n",
        "        - A method or algorithm (inventing a technique, from undoable to doable)\n",
        "        \n",
        "     GAN framework\n",
        "\n",
        "    * _Before_ reading the main body of the paper, write down your first impression  obtained from its abstract and short introduction.\n",
        "    \n",
        "    it is a funny technical which have both generator and dector model, since both model doing better, the detector can not detect the fake sample.\n",
        "    \n",
        "    * Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
        "    \n",
        "    in recent year, there are plenty of fake technical was produced based on GAN,such as face generation and text to image.\n",
        "    \n",
        "    \n",
        "2. Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list,  compare the list with people around you who have chosen the same or a similar paper.\n",
        "\n",
        " backpropagation and dropout algorithm\n",
        " directed graphical models\n",
        " Deep belief networks\n",
        " score matching and noise-contrastive       estimation\n",
        " generative stochastic network\n",
        "\n",
        "3. (During the next 7 days) Re-consider the central problem of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMdubDy73_Jn",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Generative Adversarial Nets\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DHsGIWt3_Jo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "#\n",
        "```\n",
        "\n",
        "## Introduction\n",
        "Base on reviewing the report Generative Adversarial Nets, it provided more deeply understanding on GAN technical. The report is focusing on presenting GAN method by following the introduce to exist problem in current model, the relative background, claim the theory of Adversarial nets, the actual stage to complete the model, represent the performance of the model base on example, the benefit and drawback of GAN and concluding GAN technical for providing hypothesis for future work.\n",
        "\n",
        "This report will represent GAN technical base on deeply understanding of report Generative Adversarial Nets. It will focus on content, innovation, technical quality, application and X-factor and presentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X63K3XhK3_Jp",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPFABULK3_Jq",
        "colab_type": "text"
      },
      "source": [
        "The report Generative Adversarial Nets introduced a new method for producing generative model. The GAN technical is produced for resolving the exist problem of deep generative models. In deep learning, backpropagation algorithms refers to a family of methods which used to efficiently train artificial neural networks(Hecht-Nielsen, 1992), dropout algorithms is a regularization technique and used to reduce overfitting in neural networks(Srivastava, Hinton and Krizhevsky, et al., 2014), based on backpropagation and dropout algorithms, there is a great success in resolving the complex, high-dimensional and rich sensory data into specific label. However, deep generative model enjoys less benefit from it, because there is much complex computation for running maximum likelihood estimation and related strategies, and because it is hard to enjoy the benefits of piecewise linear units during the generative context.\n",
        "\n",
        "The new technical GAN is provided to avoid those problem. An example is provided in the report to explain GAN, the model can be divided by two section which are discriminative model and generative model. The generative model can be understanding as a fake team who are trying to produce plenty of fake products, the discriminative model can be known as a police team who are trying to detect the fake produce. By driving the competition, both team trying to improve their skill to fake or detect until it is hard to detect fake or true product. \n",
        "\n",
        "Its related work has been discussed which include the explain to undirected graphical model which is replaceable representation of a joint distribution (Murray & Ghahramani, 2004), deep belief networks(DBNs) which include one undirected layer and several directed layer is hard to compute when associate to both directed and undirected model, score matching and noise-contrastive estimation which can be the replacement of bounding the log-likelihood and generative stochastic network(GSN) which required train a generative machine to supply samples from desired distribution. By comparing the GSN with adversarial nets, adversarial nets are not required Markov chain because its generation section is not required feedback loop, there it is better in enjoying the benefit of piecewise linear units. Therefore, it increases the performance of backpropagation, but it is also a problem with unbounded activation when used in a feedback loop.\n",
        "\n",
        "The theory of adversarial net was introduced, and relative algorithm was presented. Three databases were used to evaluate the adversarial model. Based on a series of work, its advantage and disadvantages were discovered which include disadvantages in lacking explicit representation of pg(x), requiring synchronized well between G and D during training and advantage in not requiring Markov chains, updating generator network by gradients flow based on discriminator and its distribution are able to be represented clear. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqAcsRcr3_Jr",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4G6w9Lo3_Js",
        "colab_type": "text"
      },
      "source": [
        "This report is presenting a new generative model which can resolve some problems in existing deep generative model which include difficult in computing when there is maximum likelihood estimation and related strategies and hard to enjoy the benefit of piecewise linear units in the generative context. The GAN technical include both generator and discriminator model, backpropagation and dropout algorithms was using in the report to train both models, the sample from the generative model using only forward propagation.\n",
        "\n",
        "A serious of exploration has showed to present the innovation to adversarial net. First, the undirected graphical model which is presented as a replacement of directed graphical model is hard to working with its partition function and gradient even base on Markov chain Monte Carlo (MCMC).Second, deep belief networks which include single undirected layer and several directed layers have problem with associate both undirected and directed models. Third, both denoising auto-encoders and contractive autoencoders have similar learning rule with score matching and noise-contrastive estimation which is not required approximate or bound log-likelihood, but there are also some problems with NCE based on fixed noise distribution that the learning speed is decreasing after the model learnt most correct distribution. Final, generative stochastic network (GSN) is not required defining a probability distribution explicitly and able to be trained by backpropagation. but comparing GSN with adversarial nets, adversarial nets are better in enjoying the benefit of piecewise linear units and does not required Markov chain based on there is no requirements in feedback loop during generation, however, there is also a problem with adversarial nets which is unbounded activation when used in a feedback loop.\n",
        "\n",
        "\n",
        "\n",
        "GAN is a new framework which working with both generator and discriminator. Based on min-max function, max V (D, G) can be explained as maximum detect that the sample from true data or generator when there is fixed generator, when consider min (max V (D, G)), it also can be explained as minimum the difference of sample from true data and generator when there is fixed discriminator. This technical provide a new method to train a model, the model will be trained successful since the discriminator is not able to detect the sample from true data or generator. It resolves the computing problem of previous deep generative models in estimation maximum likelihood and similar strategies by itself. \n",
        "\n",
        "In concluding those work, its innovation including resolve the computing problem of previous deep generative models in estimation maximum likelihood and similar strategies, resolve the problem in enjoying the benefit of piecewise linear units, remove the requirements of Markov chain, able to represent its distribution clear and potential in improvement rely on different function. All those features are presenting the viability and the potential of GAN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk-GpJtz3_Jt",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XqbgnpW3_Jt",
        "colab_type": "text"
      },
      "source": [
        "This report has a high quality in technical explanation which include the explanation of min-max function, the distribution of both generator and discriminator, the step to use the method, and explain to each stage.\n",
        "\n",
        " \n",
        "\n",
        "The min-max function showing how the framework running, D is refers to discriminator and G is refers to generator, min max V (D, G) is working for minimum difference between true data and sample that generator produced, maximum the ability that discriminator to detect the source of sample.\n",
        "\n",
        " \n",
        "Figure 1, training distribution in GAN\n",
        "\n",
        "Image (figure 1) showing both distribution in true data (black dotted line) and generated data (generated line), blue dashed line showing the discriminative distribution. In graph D, its is hard to detect that sample from generator or true data.\n",
        "\n",
        " \n",
        "\n",
        "The stage to build the model has been showed in a clear and logical way, there are two for loop were used to explain the stage, in addition, a serious of explain were used to proof its running.\n",
        "\n",
        "However, there is also a quality problem in presenting the method by three normal database which include MNIST, Toronto Face Database (TFD) and CIFAR-10.\n",
        " \n",
        "Figure 2, Parzen window-based log-likelihood estimates\n",
        "\n",
        "Figure 2 showing adversarial nets in both data set have higher variance, the estimating method (Parzen window-based log-likelihood estimates) is not work well for adversarial nets and it is also having less performance in high dimensional spaces. It required a new estimating which can evaluate adversarial nets.\n",
        "\n",
        " \n",
        "Figure 3, Visualization of samples from the model\n",
        "\n",
        "In the report, figure 3 was used to present the potential of adversarial nets, most widely used database were used to present the visualization of samples from the model.\n",
        "\n",
        "In concluding, this report has a high technical quality in presenting the concept of the method but also lacking a way to estimating or evaluating the adversarial nets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0kPdcgz3_Ju",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-yuRuRx3_Jv",
        "colab_type": "text"
      },
      "source": [
        "Generative Adversarial Nets (GAN) have most widely application domain. In the report, it is showing the possibility that GAN working in the field of image generation. This type of works can also apply to all kinds of data sources such as face generation (Huang, Zhang & Li, et al., 2017), image classification, sound detection and sound generation. Based on research, many kinds of GAN models were produced for specific field such as LSGAN, WGAN, WGAN-GP, DRGAN, CGAN, TPGAN, Cycle GAN and Disco-GAN. Following will introduce two different application.\n",
        "\n",
        " \n",
        "Figure 4, example of application in cycle GAN\n",
        "\n",
        "Cycle GAN is a method based on GAN which Provides an unsupervised image translation method (Zhu, Park & Isola, et al., 2017). The most widely application domain of this method is style change. Figure 4 is showing the main application of this method.\n",
        "\n",
        " \n",
        "Figure 5, example of application in cycle Disco-GAN\n",
        "\n",
        "Disco-GAN is another method based on GAN which can learn the relationship with cross domain without the requirements of label tags and image pairing (Kim, Cha, Kim & Lee, et al., 2017). The usage of this method includes style transform such as figure 5, the style of shoes can transform into bags.\n",
        "\n",
        "GAN technical is becoming more developed, plenty problems about it is resolving by more technical such as LSGAN trying to resolve the gradient disappearance problem of GAN, WGAN trying to resolve both gradient disappearance and instability problem. Also, the problem of estimating GAN model has also been resolved by several new estimating attributes (Xu, Huang, G & Yuan, et al., 2018).\n",
        "\n",
        "An interesting field of GAN is text to image, based on the usage of NLP, attn GAN is showing high performance in text-to image (Xu, Zhang & Huang, et al., 2018), which means an image can be produced by a description sentence. In addition, another interesting field of GAN is repair broken image(Liu, Reda & Shih, et al., 2018), for example, GAN is allowed to generated image based on limited image, if there is half side of face was detected by camera, GAN is allowed to generating another half side and used for increased the performance of face detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7GYCwwx3_Jv",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0gr7SRz3_Jw",
        "colab_type": "text"
      },
      "source": [
        "The report provided a clear presentation about the basic theory of GAN which include a two-player game to introduce the workflow of GAN, the innovation to GAN, the min-max function to present the target of both players, the distribution plot to show the working process of both model, the stage to build the model, the proof of the theory and the example to present the model. It makes the framework of GAN getting easier to understand its process, and very clear in most of detail, deeply understand its theory and able to build it. However, there are also some drawbacks which include unclear evaluation of the model, powerless image Comparation and limited advantaged and disadvantage analyst. In concluding this report, it showing a great work in developing and introducing new framework, there is less experience in estimating or evaluation its model, but in recent years, there are a lot of developed report are presenting to improve its performance, supply new estimating method and widely apply to more field.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-8sH9UB3_Jx",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "Hecht-Nielsen, R., 1992. ‘Theory of the backpropagation neural network’. In Neural networks for perception, pp. 65-93.\n",
        "\n",
        "Huang, R., Zhang, S., Li, T. and He, R., 2017. ‘Beyond face rotation: Global and local perception gan for photorealistic and identity preserving frontal view synthesis’. In Proceedings of the IEEE International Conference on Computer Vision, pp. 2439-2448.\n",
        "\n",
        "Kim, T., Cha, M., Kim, H., Lee, J.K. and Kim, J., 2017, August. ‘Learning to discover cross-domain relations with generative adversarial networks’. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 1857-1865. \n",
        "\n",
        "Liu, G., Reda, F.A., Shih, K.J., Wang, T.C., Tao, A. and Catanzaro, B., 2018. ‘Image inpainting for irregular holes using partial convolutions’. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 85-100.\n",
        "\n",
        "Murray, I. and Ghahramani, Z., 2004, July. ‘Bayesian learning in undirected graphical models: approximate MCMC algorithms’. In Proceedings of the 20th conference on Uncertainty in artificial intelligence, pp. 392-399.\n",
        "\n",
        "Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. and Salakhutdinov, R., 2014. ‘Dropout: a simple way to prevent neural networks from overfitting’. The journal of machine learning research, vol. 15, no. 1, pp.1929-1958.\n",
        "\n",
        "Xu, Q., Huang, G., Yuan, Y., Guo, C., Sun, Y., Wu, F. and Weinberger, K., 2018. ‘An empirical study on evaluation metrics of generative adversarial networks’. arXiv.\n",
        "\n",
        "Xu, T., Zhang, P., Huang, Q., Zhang, H., Gan, Z., Huang, X. and He, X., 2018. ‘Attngan: Fine-grained text to image generation with attentional generative adversarial networks’. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1316-1324.\n",
        "\n",
        "Zhu, J.Y., Park, T., Isola, P. and Efros, A.A., 2017. ‘Unpaired image-to-image translation using cycle-consistent adversarial networks’. In Proceedings of the IEEE international conference on computer vision pp. 2223-2232.\n"
      ]
    }
  ]
}
